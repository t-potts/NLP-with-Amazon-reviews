{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "#plt.style.use('seaborn')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads a subcategory of Amazon reviews into a pandas dataframe, and saves 2000 rows as a .pkl file.\n",
    "\n",
    "Restarting Kernal while only running the following cell allows EDA without excessive memory use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 20630: expected 15 fields, saw 22\\nSkipping line 28172: expected 15 fields, saw 22\\nSkipping line 54791: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 75419: expected 15 fields, saw 22\\nSkipping line 104832: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 138464: expected 15 fields, saw 22\\nSkipping line 194849: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 201568: expected 15 fields, saw 22\\nSkipping line 242567: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 493585: expected 15 fields, saw 22\\nSkipping line 502478: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 660750: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780268, 16)\n"
     ]
    }
   ],
   "source": [
    "#Set 'small_sample_pickled' to False to create'data/small_df.pkl'\n",
    "small_sample_pickled = True\n",
    "\n",
    "if not small_sample_pickled:\n",
    "    df = pd.read_csv('data/gaming_reviews.tsv', sep='\\t', error_bad_lines=False)\n",
    "    df['text'] = df.review_headline + df.review_body\n",
    "    \n",
    "    #Drops any text that has a NaN\n",
    "    #df = df[~df.text.isnull()].reset_index(drop=True)\n",
    "    #df = df[['text', 'star_rating']]\n",
    "    \n",
    "    print(df.shape)\n",
    "    df = df[0:10000]\n",
    "    df.to_pickle('data/small_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"data/small_df.pkl\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Definitely a silent mouse... Not a single click was heardLoved it,  I didn't even realise it was a gaming mouse,  I typed in &#34;silent mouse&#34; and selected this one. It is perfect and looks pretty cool as well. Now my boyfriend's gaming is wonderfully comfortably silent :) . Think I might just get one for myself.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The review_headline and review_body columns will both be useful for prediction.\n",
    "Review date might be useful as well, such as day of the week reviewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portions of ratings\n",
      "1: 0.10\n",
      "2: 0.04\n",
      "3: 0.07\n",
      "4: 0.13\n",
      "5: 0.66\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creates a list with the number of ratings per star\n",
    "rating_count_list = []\n",
    "possible_ratings = [1, 2, 3, 4, 5]\n",
    "\n",
    "for rating in possible_ratings:\n",
    "    rating_count_list.append(df[df['star_rating'] == rating].shape[0])\n",
    "    \n",
    "#Creates array that stores fraction of the total star values\n",
    "rating_proportion = np.array(rating_count_list)/sum(rating_count_list)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(possible_ratings, rating_count_list)\n",
    "\n",
    "ax.set_xlabel('Star rating')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Number of ratings per star value')\n",
    "\n",
    "print('Portions of ratings')\n",
    "print('1: {:0.2f}'.format(rating_proportion[0]))\n",
    "print('2: {:0.2f}'.format(rating_proportion[1]))\n",
    "print('3: {:0.2f}'.format(rating_proportion[2]))\n",
    "print('4: {:0.2f}'.format(rating_proportion[3]))\n",
    "print('5: {:0.2f}'.format(rating_proportion[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_chars = \".?,!;:\\\"'()\" \n",
    "rgx = re.compile('[%s]' % strip_chars)\n",
    "\n",
    "def process_str(row):\n",
    "\n",
    "    body_list = []\n",
    "    try:\n",
    "        for word in row.lower().split(): \n",
    "            body_list.append(rgx.sub('', word))\n",
    "        return body_list\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count vectorizes text into a sparse vector\n",
    "cv = CountVectorizer(strip_accents='ascii')\n",
    "sparse_vec = cv.fit_transform(df.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_model(X_train):\n",
    "    '''\n",
    "    defines autoencoder model\n",
    "    input: X_train (2D np array)\n",
    "    output: autoencoder (compiled autoencoder model)\n",
    "    '''\n",
    "    # this is our input placeholder\n",
    "    input_img = Input(shape=(X_train[0].shape[1],))\n",
    "\n",
    "    # first encoding layer\n",
    "    encoded1 = Dense(units = 256, activation = 'relu', name='layer1_256')(input_img)\n",
    "\n",
    "    # second encoding layer\n",
    "    # note that each layer is multiplied by the layer before\n",
    "    encoded2 = Dense(units = 64, activation='relu', name='layer2_64')(encoded1)\n",
    "\n",
    "    # first decoding layer\n",
    "    decoded1 = Dense(units = 256, activation='relu', name='layer3_256')(encoded2)\n",
    "\n",
    "    # second decoding layer - this produces the output\n",
    "    decoded2 = Dense(units = X_train[0].shape[1], activation='sigmoid', name='layer4_output')(decoded1)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = Model(input_img, decoded2)\n",
    "\n",
    "    # compile model\n",
    "    autoencoder.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mse'])\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split for small sample size\n",
    "test_stop_index = int(sparse_vec.shape[0] * 0.1)\n",
    "X_test = sparse_vec[0:test_stop_index]\n",
    "y_test = np.array(df.star_rating)[0:test_stop_index]\n",
    "\n",
    "X_train = sparse_vec[test_stop_index:]\n",
    "y_train = np.array(df.star_rating)[test_stop_index:]\n",
    "\n",
    "#One hot encoding star rating into array for transfer-learned neural net\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "enc.fit(y_test.reshape(-1,1))\n",
    "y_test = enc.transform(y_test.reshape(-1,1)).toarray()\n",
    "y_train = enc.transform(y_train.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, batch_size, y=[]):\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    shuffle_index = np.arange(np.shape(X)[0])\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    \n",
    "    while 1:\n",
    "        index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[index_batch]\n",
    "        X_batch = X_batch.toarray()\n",
    "        counter += 1\n",
    "        \n",
    "        if y == []:\n",
    "            yield X_batch, X_batch\n",
    "        else:\n",
    "            yield X_batch, y[index_batch]\n",
    "        \n",
    "        \n",
    "        if (counter > number_of_batches):\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tyler/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/tyler/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_2 to have shape (10485,) but got array with shape (17275,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f2f3ddcd130a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test mse = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_2 to have shape (10485,) but got array with shape (17275,)"
     ]
    }
   ],
   "source": [
    "autoencoder_model_created = True\n",
    "model_path = 'models/basic_autoencoder1.h5'\n",
    "\n",
    "if not autoencoder_model_created:\n",
    "    model = autoencoder_model(X_train)\n",
    "\n",
    "    batch_size = 1000\n",
    "    nb_epoch = 10\n",
    "    samples_per_epoch = 10\n",
    "\n",
    "    # instantiate callbacks\n",
    "    tensorboard = TensorBoard(log_dir='./autoencoder_logs', histogram_freq=2, batch_size=batch_size, write_graph=True, write_grads=True, write_images=True)\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "    # try different number of epochs - 10 gives good performanace \n",
    "    \"\"\"model.fit(X_train, X_train, epochs=10, batch_size=batch_size, verbose=1,\n",
    "              validation_split=0.1, callbacks = [earlystopping, tensorboard])\"\"\" # cross val to estimate test error\n",
    "\n",
    "\n",
    "    model.fit_generator(generator=batch_generator(X_train, batch_size),\n",
    "                        epochs=nb_epoch,\n",
    "                        samples_per_epoch=samples_per_epoch, validation_data=validation_generator)\n",
    "\n",
    "\n",
    "    scores = model.evaluate(X_test, X_test)\n",
    "    print('Test mse = {}'.format(scores[0]))\n",
    "\n",
    "    X_test_decoded = model.predict(X_test)\n",
    "    \n",
    "    model.save(model_path)\n",
    "\n",
    "else:\n",
    "    model = load_model(model_path)\n",
    "    scores = model.evaluate(X_test, X_test)\n",
    "    print('Test mse = {}'.format(scores[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(model.layers[i].name)\n",
    "    model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = model.layers[3].output\n",
    "ll = Dense(units = 64, activation='relu', name='layer4_256')(ll)\n",
    "ll = Dense(5,activation=\"hard_sigmoid\", name='star_classification')(ll)\n",
    "new_model = Model(inputs=model.input, outputs=ll)\n",
    "\n",
    "new_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=[metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "nb_epoch = 15\n",
    "samples_per_epoch = 10\n",
    "\n",
    "# instantiate callbacks\n",
    "tensorboard = TensorBoard(log_dir='./autoencoder_logs', histogram_freq=2, batch_size=batch_size, write_graph=True, write_grads=True, write_images=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "# try different number of epochs - 10 gives good performanace \n",
    "\"\"\"model.fit(X_train, X_train, epochs=10, batch_size=batch_size, verbose=1,\n",
    "          validation_split=0.1, callbacks = [earlystopping, tensorboard])\"\"\" # cross val to estimate test error\n",
    "\n",
    "\n",
    "new_model.fit_generator(generator=batch_generator(X_train, batch_size, y_train),\n",
    "                    epochs=nb_epoch,\n",
    "                    steps_per_epoch=samples_per_epoch)\n",
    "\n",
    "\n",
    "scores = new_model.evaluate(X_test, y_test)\n",
    "print('Test accuracy = {}'.format(scores[1]))\n",
    "\n",
    "X_test_decoded = new_model.predict(X_test)\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = new_model.predict_on_batch(X_test.toarray())\n",
    "y_pred[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3aaf935e6aec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(y_test.reshape(-1,1))\n",
    "enc.transform(y_test.reshape(-1,1)).toarray()\n",
    "enc.transform(y_train.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
